{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgD7kAe9SG8i"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BLVk-uMTiiD",
        "outputId": "1f3e80be-e3bc-4829-f0e6-35765bfcbe48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agQF8Cf1SG8k"
      },
      "outputs": [],
      "source": [
        "# using selenium\n",
        "\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Function to extract property details from a link\n",
        "def extract_property_details(link, headless=True):\n",
        "\n",
        "    # Custom headers\n",
        "    headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 OPR/77.0.4054.254\",\n",
        "    \"Accept\": \"*/*\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
        "    \"Accept-Language\": \"en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7,mr;q=0.6\",\n",
        "    \"Referer\": \"https://www.99acres.com/\",\n",
        "    \"Sec-CH-UA\": '\"Not)A;Brand\";v=\"99\", \"Google Chrome\";v=\"127\", \"Chromium\";v=\"127\"',\n",
        "    \"Sec-CH-UA-Mobile\": \"?0\",\n",
        "    \"Sec-CH-UA-Platform\": '\"Windows\"',\n",
        "    \"Sec-Fetch-Dest\": \"script\",\n",
        "    \"Sec-Fetch-Mode\": \"no-cors\",\n",
        "    \"Sec-Fetch-Site\": \"cross-site\",\n",
        "    \"If-None-Match\": 'W/328252ecd0b0d0a8919b649891f578f2',\n",
        "    }\n",
        "\n",
        "    # Configure Chrome options\n",
        "    chrome_options = Options()\n",
        "    if headless:\n",
        "        chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
        "    chrome_options.add_argument(\"--disable-gpu\")\n",
        "    chrome_options.add_argument(\"--pageLoadStrategy=none\")\n",
        "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    chrome_options.add_argument(\"--no-sandbox\")\n",
        "    chrome_options.add_argument(f\"user-agent={headers['User-Agent']}\")\n",
        "\n",
        "    # Start Chrome browser with options\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "    driver.get(link)\n",
        "\n",
        "    # Wait for the page to load\n",
        "    time.sleep(2)\n",
        "\n",
        "    # Get the page source and parse it with BeautifulSoup\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "    # Close the driver after scraping\n",
        "    driver.quit()\n",
        "\n",
        "    # Extract details\n",
        "    facing = soup.find('span', {'id': 'facingLabel'}).text.strip() if soup.find('span', {'id': 'facingLabel'}) else None\n",
        "\n",
        "    price_tag = soup.find_all('span', {'class': 'component__pdPropValue'})\n",
        "    price = price_tag[0].text.strip() if price_tag else None\n",
        "\n",
        "    bedroom = soup.find('span', {'id': 'bedRoomNum'}).text.strip() if soup.find('span', {'id': 'bedRoomNum'}) else None\n",
        "    bathroom = soup.find('span', {'id': 'bathroomNum'}).text.strip() if soup.find('span', {'id': 'bathroomNum'}) else None\n",
        "    balcony = soup.find('span', {'id': 'balconyNum'}).text.strip() if soup.find('span', {'id': 'balconyNum'}) else None\n",
        "    extra_room = soup.find('span', {'id': 'additionalRooms'}).text.strip() if soup.find('span', {'id': 'additionalRooms'}) else \"No\"\n",
        "\n",
        "    address_tag = soup.find('div', {'class': 'component__pdDescAdd'})\n",
        "    address = address_tag.find('i', {'id': 'address'}).text.strip() if address_tag else None\n",
        "\n",
        "    age = soup.find('span', {'id': 'agePossessionLbl'}).text.strip() if soup.find('span', {'id': 'agePossessionLbl'}) else None\n",
        "\n",
        "    overlooking = soup.find('span', {'id': 'overlooking'}).text.strip() if soup.find('span', {'id': 'overlooking'}) else None\n",
        "\n",
        "    corner_property = soup.find('span', {'id': 'Corner_Property'}).text.strip() if soup.find('span', {'id': 'Corner_Property'}) else None\n",
        "\n",
        "    transition_type = soup.find('span', {'id': 'Transact_Type_Label'}).text.strip() if soup.find('span', {'id': 'Transact_Type_Label'}) else None\n",
        "\n",
        "    furnishing = soup.find('span', {'id': 'Furnish_Label'}).text.strip() if soup.find('span', {'id': 'Furnish_Label'}) else None\n",
        "\n",
        "    floor_number = soup.find('span', {'id': 'floorNumLabel'}).text.strip() if soup.find('span', {'id': 'floorNumLabel'}) else None\n",
        "\n",
        "    persqft = soup.find('div', {'class': 'component__pdPropArea pd__pdPropArea'}).text.strip() if soup.find('div', {'class': 'component__pdPropArea pd__pdPropArea'}) else None\n",
        "\n",
        "    description_tag = soup.find('span', {'id': 'description'})\n",
        "    if description_tag:\n",
        "        description_text = description_tag.text.strip()\n",
        "        parts = description_text.split(\"Additional details :\")\n",
        "        main_description = parts[0].strip() if len(parts) > 0 else None\n",
        "        additional_details = \"Additional details: \" + parts[1].strip() if len(parts) > 1 else None\n",
        "    else:\n",
        "        main_description = \"Description not found\"\n",
        "        additional_details = \"Description not found\"\n",
        "\n",
        "    nearby_elements = soup.find_all('span', {'class': 'NearByLocation__infoText'})\n",
        "    nearby_locations = [element.text.strip() for element in nearby_elements]\n",
        "\n",
        "    features_div = soup.find('div', {'class': 'component__features pd__pdBlock', 'data-label': 'FACILITIES'})\n",
        "    features = []\n",
        "    if features_div:\n",
        "        features_list = features_div.find('ul', {'id': 'features'})\n",
        "        if features_list:\n",
        "            features = [li.find('div').text.strip() for li in features_list.find_all('li')]\n",
        "\n",
        "    row_data = {\n",
        "        'Facing': facing,\n",
        "        'Price': price,\n",
        "        'No_Bedroom': bedroom,\n",
        "        'No_Bathroom': bathroom,\n",
        "        'No_Balcony': balcony,\n",
        "        'Age': age,\n",
        "        'Overlooking': overlooking,\n",
        "        'Corner_Property': corner_property,\n",
        "        'Transition_Type': transition_type,\n",
        "        'Furnishing': furnishing,\n",
        "        'Address': address,\n",
        "        'Floor Number': floor_number,\n",
        "        'Per Sqft': persqft,\n",
        "        'Main Description': main_description,\n",
        "        'Additional Details': additional_details,\n",
        "        'Extra Room': extra_room,\n",
        "        'Nearby Locations': nearby_locations,\n",
        "        'Features': features\n",
        "    }\n",
        "\n",
        "    return row_data\n",
        "\n",
        "# Example usage\n",
        "property_data = extract_property_details('https://www.99acres.com/2-bhk-bedroom-apartment-flat-for-sale-in-green-court-sector-90-gurgaon-690-sq-ft-r1-spid-B74992655')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClflInYxSG8n",
        "outputId": "438e76ad-4d1a-4901-c43b-3bfd9e2bd39b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Facing': 'North', 'Price': '70 Lac', 'No_Bedroom': '2 Bedrooms', 'No_Bathroom': '1 Bathroom', 'No_Balcony': '1 Balcony', 'Age': '1 to 5 Year Old', 'Overlooking': 'Park/Garden,Main Road,Club,Pool,Others,Sea facing', 'Corner_Property': 'Yes', 'Transition_Type': 'Resale', 'Furnishing': 'Semifurnished', 'Address': '0008, Sector 90, Gurgaon', 'Floor Number': '6th\\xa0\\xa0 of 14 Floors', 'Per Sqft': '@ 10,144 per sq.ft.', 'Main Description': 'Located in the popular residential address of sector 90 gurgaon, green court is one of the most preferred destination for apartments in gurgaon. This 2 bhk flat is your ticket to be a part of this community. Constructed on a super built up area of 690 sq.Ft., the flat comprises 2 bedroom(s), 1 bathr...', 'Additional Details': None, 'Extra Room': 'No', 'Nearby Locations': ['Baba Kanala Chowk', 'Pataudi Rd', 'Gurukul Preschool', 'Yaduvanshi Shiksha Niketan', 'Bharat Ram Global School', 'RPS International School', 'ICICI ATM', 'Silver Streak Hospital', 'Arc Multi Speciality', 'Sanjeevani Hospital', 'HDFC Bank', 'Sai Sports Club cricket ground', 'Nawada Cricket Accadmy', 'HP PETROL PUMP Unnamed Rd', 'INOX Cinema'], 'Features': ['Security / Fire Alarm', 'Feng Shui / Vaastu Compliant', 'Intercom Facility', 'Lift(s)', 'High Ceiling Height', 'Maintenance Staff', 'False Ceiling Lighting', 'Water Storage', 'Bank Attached Property', 'Visitor Parking', 'Park', 'Security Personnel', 'Natural Light', 'Internet/wi-fi connectivity', 'Airy Rooms', 'Spacious Interiors', 'Low Density Society', 'Waste Disposal', 'Rain Water Harvesting', 'Water softening plant']}\n"
          ]
        }
      ],
      "source": [
        "print(property_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nBrVeXGJrDE"
      },
      "outputs": [],
      "source": [
        "def process_page(pagenumber):\n",
        "\n",
        "\n",
        "    url = \"https://www.99acres.com/search/property/buy?city=8&res_com=R&preference=S&referrer_section=BROWSE_BY_PROP_TYPE&property_type=1&src=HP_WIDGET&sortby=dominance&dominantBedroom=2&dominantMinBudget=&dominantMaxBudget=&page={}\".format(pagenumber)\n",
        "\n",
        "    headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\",\n",
        "    \"Accept\": \"*/*\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
        "    \"Accept-Language\": \"en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7,mr;q=0.6\",\n",
        "    \"Referer\": \"https://www.99acres.com/\",\n",
        "    \"Sec-CH-UA\": '\"Not)A;Brand\";v=\"99\", \"Google Chrome\";v=\"127\", \"Chromium\";v=\"127\"',\n",
        "    \"Sec-CH-UA-Mobile\": \"?0\",\n",
        "    \"Sec-CH-UA-Platform\": '\"Windows\"',\n",
        "    \"Sec-Fetch-Dest\": \"script\",\n",
        "    \"Sec-Fetch-Mode\": \"no-cors\",\n",
        "    \"Sec-Fetch-Site\": \"cross-site\",\n",
        "    \"If-None-Match\": 'W/328252ecd0b0d0a8919b649891f578f2',\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers )\n",
        "    soup = BeautifulSoup(response.text, 'lxml')\n",
        "    flats = soup.find_all('div', {'class': 'tupleNew__tupleWrap tupleNew__PremH'})\n",
        "    all_data = []\n",
        "\n",
        "\n",
        "    for flat in flats:\n",
        "\n",
        "        link = flat.find('a', {'class': 'tupleNew__propertyHeading ellipsis'})['href']\n",
        "        # Extract property details\n",
        "        time.sleep(2)\n",
        "        no_of_room = flat.find_all('span', {'class': 'tupleNew__area1Type'})\n",
        "        area_type = flat.find('div', {'class': 'tupleNew__areaType'}).text.strip() if flat.find('div', {'class': 'tupleNew__areaType'}) else None\n",
        "        given_area = no_of_room[0].text.strip() if len(no_of_room) > 0 else None\n",
        "        property_type = flat.find('h2', {'class': 'tupleNew__propType'}).text.strip() if flat.find('h2', {'class': 'tupleNew__propType'}) else \"Information Not Available\"\n",
        "        dealer = flat.find('div', {'class': 'tupleNew__pbL2 ellipsis'}).text.strip() if flat.find('div', {'class': 'tupleNew__pbL2 ellipsis'}) else \"Information Not Available\"\n",
        "        society_name = flat.find('div', {'class': 'tupleNew__locationName ellipsis'}).text.strip() if flat.find('div', {'class': 'tupleNew__locationName ellipsis'}) else \"Information Not Available\"\n",
        "\n",
        "        data = extract_property_details(link)\n",
        "        time.sleep(2)\n",
        "        data['AreaType'] = area_type\n",
        "        data['Given Area'] = given_area\n",
        "        data['Property Type'] = property_type\n",
        "        data['Dealer'] = dealer\n",
        "        data['Society Name'] = society_name\n",
        "\n",
        "        all_data.append(data)\n",
        "\n",
        "    df = pd.DataFrame(all_data)\n",
        "    return df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLx3EcBxSG8s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bfBVjoEsJ-D",
        "outputId": "75d9882b-fb47-44bf-a527-4cab2c0b07ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14404, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "final = pd.read_csv('/content/drive/MyDrive/datasets_large/final_data.csv')\n",
        "final.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ2CbzFLekD4",
        "outputId": "83df9d50-d569-457c-ad15-c573e308478e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the start page number: 548\n",
            "Processing page 548...\n"
          ]
        }
      ],
      "source": [
        "start_page = int(input(\"Enter the start page number: \"))\n",
        "end_page = start_page + 0\n",
        "\n",
        "drive_path = '/content/drive/MyDrive/datasets_large/'\n",
        "\n",
        "# Loop through pages and extract data\n",
        "for page_number in range(start_page, end_page + 1):\n",
        "    try:\n",
        "        print(f\"Processing page {page_number}...\")\n",
        "        df = process_page(page_number)\n",
        "\n",
        "        if df is None or df.empty:\n",
        "            print(f\"No data extracted from page {page_number}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        final = pd.concat([final, df], ignore_index=True)\n",
        "\n",
        "        # Save progress to a CSV file named with start and end page numbers\n",
        "        df.to_csv(f'{drive_path}data_{start_page}_{end_page}.csv', index=False)\n",
        "\n",
        "        # Also append the data to final_data.csv\n",
        "        with open(f'{drive_path}final_data.csv', 'a', newline='', encoding='utf-8') as f:\n",
        "            df.to_csv(f, header=f.tell() == 0, index=False)\n",
        "\n",
        "        # Delay between requests to avoid getting blocked\n",
        "        time.sleep(2)  # Adjust as needed\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred on page {page_number}: {e}\")\n",
        "\n",
        "        # Save progress to a CSV file before breaking\n",
        "        final.to_csv(f'{drive_path}data_{start_page}_{end_page}_error.csv', index=False)\n",
        "        break\n",
        "\n",
        "# Longer delay after processing the chunk\n",
        "time.sleep(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSUc-gTBxFar",
        "outputId": "4bf7cb52-9c8a-422f-e4bb-dc320f31aeb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14442, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pABOepdH6LGU"
      },
      "outputs": [],
      "source": [
        "final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSbR7U27c8fe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aglmQ3P3SG82"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}